import streamlit as st
import pandas as pd
import io
import numpy as np
import math

# --- ãƒãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ³é–¢æ•° (å¤‰æ›´ãªã—) ---
def haversine(lat1, lon1, lat2, lon2):
    if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2): return np.nan
    R=6371.0; lat1_rad,lon1_rad,lat2_rad,lon2_rad = map(math.radians,[lat1,lon1,lat2,lon2])
    dlon=lon2_rad-lon1_rad; dlat=lat2_rad-lat1_rad
    a=math.sin(dlat/2)**2 + math.cos(lat1_rad)*math.cos(lat2_rad)*math.sin(dlon/2)**2
    c=2*math.atan2(math.sqrt(a),math.sqrt(1-a)); distance=R*c; return distance

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: æ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤åˆ¥ (â˜…â˜…â˜… ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä¿®æ­£ â˜…â˜…â˜…) ---
def read_csv_with_fallback(bytes_data, filename):
    last_exception = None
    encodings_to_try = ['utf-8-sig', 'cp932', 'utf-8']
    for encoding in encodings_to_try:
        try:
            bytes_data.seek(0)
            df = pd.read_csv(bytes_data, encoding=encoding, low_memory=False)
            st.write(f"    - ã€Œ{filename}ã€ã‚’ {encoding} ã§èª­ã¿è¾¼ã¿æˆåŠŸã€‚")
            return df
        except UnicodeDecodeError as e:
            last_exception = e
            st.write(f"    - ã€Œ{filename}ã€: {encoding} ã§ã®èª­ã¿è¾¼ã¿å¤±æ•—ã€‚")
        except Exception as e: # â˜…â˜…â˜… ã“ã“ã® except ãƒ–ãƒ­ãƒƒã‚¯ â˜…â˜…â˜…
            last_exception = e # â˜…â˜…â˜… ã“ã®è¡ŒãŒã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª â˜…â˜…â˜…
            st.write(f"    - ã€Œ{filename}ã€: {encoding} ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ ({type(e).__name__})ã€‚") # â˜…â˜…â˜… ã“ã®è¡Œã‚‚ â˜…â˜…â˜…
    # ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§å¤±æ•—ã—ãŸå ´åˆ
    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{filename}ã€ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {last_exception}")
    raise ValueError(f"æ–‡å­—ã‚³ãƒ¼ãƒ‰åˆ¤åˆ¥ä¸èƒ½ ({filename})") from last_exception

# --- Streamlit ã‚¢ãƒ—ãƒªæœ¬ä½“ ---
st.set_page_config(page_title="CO2æ’å‡ºé‡è¨ˆç®—", layout="wide")
st.title("ğŸšš CO2æ’å‡ºé‡è¨ˆç®—ãƒ„ãƒ¼ãƒ«")
st.write("""
è²©å£²å®Ÿç¸¾æ˜ç´°CSVï¼ˆè¤‡æ•°å¯ï¼‰ã¨ã€ç·¯åº¦çµŒåº¦ãŒä»˜ä¸ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆCSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
è·é›¢ã¨CO2æ’å‡ºé‡ï¼ˆãƒˆãƒ©ãƒƒã‚¯è¼¸é€å‰æï¼‰ã‚’è¨ˆç®—ã—ã€è·é›¢600kmä»¥ä¸‹ã®çµæœã¨600kmè¶…ã®çµæœï¼ˆç•°å¸¸å€¤ã®å¯èƒ½æ€§ï¼‰ã‚’åˆ¥ã€…ã«å‡ºåŠ›ã—ã¾ã™ã€‚
å‡¦ç†å‰å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚‚è¡¨ç¤ºã—ã€æ•´åˆæ€§ã‚’ç¢ºèªã§ãã¾ã™ã€‚
""")

# --- CO2æ’å‡ºä¿‚æ•°è¨­å®š ---
st.sidebar.markdown("### è¨ˆç®—è¨­å®š")
co2_factor = st.sidebar.number_input(
    "CO2æ’å‡ºä¿‚æ•° (g-CO2 / ãƒˆãƒ³ã‚­ãƒ­)", value=230.0, step=0.1, format="%.1f",
    help="ãƒˆãƒ©ãƒƒã‚¯è¼¸é€ã‚’æƒ³å®šã—ãŸã€1ãƒˆãƒ³ã‚­ãƒ­ã‚ãŸã‚Šã®CO2æ’å‡ºé‡(ã‚°ãƒ©ãƒ )ã€‚"
)

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
st.header("1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
col1, col2 = st.columns(2)
with col1:
    uploaded_sales_files = st.file_uploader(
        "è²©å£²å®Ÿç¸¾æ˜ç´°CSV (æœ€å¤§12å€‹)", type='csv', accept_multiple_files=True, key="sales_uploader_co2"
    )
    if uploaded_sales_files:
        if len(uploaded_sales_files) > 12: st.error(f"æœ€å¤§12å€‹ã¾ã§ã§ã™ã€‚({len(uploaded_sales_files)} å€‹é¸æŠä¸­)")
        else: st.success(f"{len(uploaded_sales_files)} å€‹ å—ä»˜å®Œäº†")
with col2:
    uploaded_geocoded_list_file = st.file_uploader(
        "ç·¯åº¦çµŒåº¦ä»˜ãã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ CSV", type='csv', key="geocoded_list_uploader"
    )
    if uploaded_geocoded_list_file: st.success("ç·¯åº¦çµŒåº¦ãƒªã‚¹ãƒˆ å—ä»˜å®Œäº†")

# --- å‡¦ç†å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
st.header("2. å‡¦ç†å®Ÿè¡Œã¨çµæœ")
all_files_uploaded = (
    uploaded_sales_files and 0 < len(uploaded_sales_files) <= 12 and uploaded_geocoded_list_file
)
res_col1, res_col2 = st.columns([1, 4])

with res_col1:
    if st.button("å‡¦ç†å®Ÿè¡Œ", disabled=not all_files_uploaded, use_container_width=True):
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
        st.session_state.co2_processing_done = False
        st.session_state.co2_input_count = 0
        st.session_state.co2_normal_result_df = None
        st.session_state.co2_normal_count = 0
        st.session_state.co2_anomaly_result_df = None
        st.session_state.co2_anomaly_count = 0
        st.session_state.co2_error_message = None
        st.session_state.co2_log_messages = []
        st.session_state.co2_button_clicked = True

        st.info("CO2æ’å‡ºé‡è¨ˆç®—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        progress_bar = st.progress(0, text="ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        log_messages = ["**å‡¦ç†ãƒ­ã‚°:**"]

        try:
            # --- 1. ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ---
            log_messages.append("--- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–‹å§‹ ---")
            files_read_count = 0
            total_files_to_read = len(uploaded_sales_files) + 1
            sales_dfs = []
            required_sales_cols = ['ä»•å…¥å…ˆã‚³ãƒ¼ãƒ‰', 'è·å—äººã‚³ãƒ¼ãƒ‰', 'åˆ†æç”¨å˜ä½æ•°é‡']
            log_messages.append("--- è²©å£²å®Ÿç¸¾ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ ---")
            for i, uploaded_file in enumerate(uploaded_sales_files):
                bytes_data = io.BytesIO(uploaded_file.getvalue())
                filename = uploaded_file.name
                log_messages.append(f"  - èª­ã¿è¾¼ã¿è©¦è¡Œ: {filename}")
                df = read_csv_with_fallback(bytes_data, filename)
                sales_dfs.append(df)
                files_read_count += 1
                progress_bar.progress(files_read_count / total_files_to_read, text=f"èª­ã¿è¾¼ã¿ä¸­: {filename}")
                log_messages.append(f"    -> èª­ã¿è¾¼ã¿å®Œäº† ({filename})")
            if not sales_dfs: raise ValueError("èª­ã¿è¾¼ã¿å¯èƒ½ãªè²©å£²å®Ÿç¸¾ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            sales_data_raw = pd.concat(sales_dfs, ignore_index=True)
            input_row_count = len(sales_data_raw)
            st.session_state.co2_input_count = input_row_count
            log_messages.append(f"--- è²©å£²å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®çµåˆå®Œäº† (åˆè¨ˆ: {input_row_count} ä»¶) ---")

            required_geocoded_cols = ['ã‚³ãƒ¼ãƒ‰ç¨®åˆ¥', 'ã‚³ãƒ¼ãƒ‰', 'ç·¯åº¦', 'çµŒåº¦']
            geocoded_list_bytes = io.BytesIO(uploaded_geocoded_list_file.getvalue())
            geocoded_list_filename = uploaded_geocoded_list_file.name
            log_messages.append(f"--- ç·¯åº¦çµŒåº¦ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ ({geocoded_list_filename}) ---")
            geocoded_list_df = read_csv_with_fallback(geocoded_list_bytes, geocoded_list_filename)
            if not all(col in geocoded_list_df.columns for col in required_geocoded_cols):
                 raise ValueError(f"ç·¯åº¦çµŒåº¦ãƒªã‚¹ãƒˆã«å¿…è¦ãªåˆ— ({', '.join(required_geocoded_cols)}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            files_read_count += 1
            progress_bar.progress(files_read_count / total_files_to_read, text=f"èª­ã¿è¾¼ã¿ä¸­: {geocoded_list_filename}")
            log_messages.append(f"    -> èª­ã¿è¾¼ã¿å®Œäº† ({geocoded_list_filename})")
            progress_bar.progress(1.0, text="å…¨ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†ï¼")

            # --- 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
            log_messages.append("--- ãƒ‡ãƒ¼ã‚¿æº–å‚™é–‹å§‹ ---")
            progress_bar.progress(0.1, text="ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")
            sales_data = sales_data_raw.copy()
            if not all(col in sales_data.columns for col in required_sales_cols):
                 missing_cols = [col for col in required_sales_cols if col not in sales_data.columns]
                 raise ValueError(f"çµåˆå¾Œã®è²©å£²å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã«å¿…è¦ãªåˆ— ({', '.join(missing_cols)}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            sales_data['ä»•å…¥å…ˆã‚³ãƒ¼ãƒ‰'] = sales_data['ä»•å…¥å…ˆã‚³ãƒ¼ãƒ‰'].astype(str).str.strip()
            sales_data['è·å—äººã‚³ãƒ¼ãƒ‰'] = sales_data['è·å—äººã‚³ãƒ¼ãƒ‰'].astype(str).str.strip()
            sales_data['åˆ†æç”¨å˜ä½æ•°é‡_ãƒˆãƒ³'] = pd.to_numeric(sales_data['åˆ†æç”¨å˜ä½æ•°é‡'], errors='coerce').fillna(0)
            log_messages.append("  - è²©å£²å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™å®Œäº†")
            geo_list = geocoded_list_df[required_geocoded_cols].copy()
            geo_list['ã‚³ãƒ¼ãƒ‰'] = geo_list['ã‚³ãƒ¼ãƒ‰'].astype(str).str.strip()
            geo_list['ç·¯åº¦'] = pd.to_numeric(geo_list['ç·¯åº¦'], errors='coerce')
            geo_list['çµŒåº¦'] = pd.to_numeric(geo_list['çµŒåº¦'], errors='coerce')
            geo_list = geo_list.dropna(subset=['ç·¯åº¦', 'çµŒåº¦'])
            geo_supplier = geo_list[geo_list['ã‚³ãƒ¼ãƒ‰ç¨®åˆ¥'] == 'ä»•å…¥å…ˆ'].drop_duplicates(subset=['ã‚³ãƒ¼ãƒ‰'], keep='first')
            geo_consignee = geo_list[geo_list['ã‚³ãƒ¼ãƒ‰ç¨®åˆ¥'] == 'è·å—äºº'].drop_duplicates(subset=['ã‚³ãƒ¼ãƒ‰'], keep='first')
            log_messages.append(f"  - ç·¯åº¦çµŒåº¦ãƒªã‚¹ãƒˆæº–å‚™å®Œäº† (ä»•å…¥å…ˆ: {len(geo_supplier)}ä»¶, è·å—äºº: {len(geo_consignee)}ä»¶)")
            log_messages.append("--- ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº† ---")
            progress_bar.progress(0.3, text="ç·¯åº¦çµŒåº¦ã®ç´ä»˜ã‘ä¸­...")

            # --- 3. ç·¯åº¦çµŒåº¦ã®ä»˜ä¸ (ãƒãƒ¼ã‚¸) ---
            merged_data = pd.merge(sales_data, geo_supplier[['ã‚³ãƒ¼ãƒ‰', 'ç·¯åº¦', 'çµŒåº¦']], left_on='ä»•å…¥å…ˆã‚³ãƒ¼ãƒ‰', right_on='ã‚³ãƒ¼ãƒ‰', how='left', suffixes=('', '_ä»•å…¥å…ˆ'))
            merged_data.rename(columns={'ç·¯åº¦': 'ä»•å…¥å…ˆ_ç·¯åº¦', 'çµŒåº¦': 'ä»•å…¥å…ˆ_çµŒåº¦'}, inplace=True)
            merged_data.drop(columns=['ã‚³ãƒ¼ãƒ‰'], inplace=True, errors='ignore') # errors='ignore' ã‚’è¿½åŠ 
            merged_data = pd.merge(merged_data, geo_consignee[['ã‚³ãƒ¼ãƒ‰', 'ç·¯åº¦', 'çµŒåº¦']], left_on='è·å—äººã‚³ãƒ¼ãƒ‰', right_on='ã‚³ãƒ¼ãƒ‰', how='left', suffixes=('', '_è·å—äºº'))
            merged_data.rename(columns={'ç·¯åº¦': 'è·å—äºº_ç·¯åº¦', 'çµŒåº¦': 'è·å—äºº_çµŒåº¦'}, inplace=True)
            merged_data.drop(columns=['ã‚³ãƒ¼ãƒ‰'], inplace=True, errors='ignore') # errors='ignore' ã‚’è¿½åŠ 
            log_messages.append("--- ç·¯åº¦çµŒåº¦ã®ç´ä»˜ã‘å®Œäº† ---")
            progress_bar.progress(0.6, text="è·é›¢è¨ˆç®—ä¸­...")

            # --- 4. è·é›¢è¨ˆç®— ---
            log_messages.append("--- è·é›¢è¨ˆç®—é–‹å§‹ (ãƒãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ³æ³•) ---")
            distances = merged_data.apply(lambda row: haversine(row.get('ä»•å…¥å…ˆ_ç·¯åº¦'), row.get('ä»•å…¥å…ˆ_çµŒåº¦'), row.get('è·å—äºº_ç·¯åº¦'), row.get('è·å—äºº_çµŒåº¦')), axis=1) # .get() ã‚’ä½¿ç”¨
            merged_data['è·é›¢_km'] = distances.fillna(0)
            log_messages.append("--- è·é›¢è¨ˆç®—å®Œäº† ---")
            progress_bar.progress(0.8, text="CO2æ’å‡ºé‡è¨ˆç®—ä¸­...")

            # --- 5. CO2æ’å‡ºé‡è¨ˆç®— ---
            log_messages.append(f"--- CO2æ’å‡ºé‡è¨ˆç®—é–‹å§‹ (ä¿‚æ•°: {co2_factor} g/ãƒˆãƒ³ã‚­ãƒ­) ---")
            merged_data['CO2æ’å‡ºé‡_g'] = merged_data['è·é›¢_km'] * merged_data['åˆ†æç”¨å˜ä½æ•°é‡_ãƒˆãƒ³'] * co2_factor
            log_messages.append("--- CO2æ’å‡ºé‡è¨ˆç®—å®Œäº† ---")

            # --- 6. çµæœã®æ•´ç†ã¨åˆ†å‰² ---
            log_messages.append("--- çµæœã®æ•´ç†ã¨åˆ†å‰²é–‹å§‹ ---")
            progress_bar.progress(0.9, text="çµæœæ•´ç†ä¸­...")
            merged_data['è·é›¢_km'] = merged_data['è·é›¢_km'].round(5)
            merged_data['CO2æ’å‡ºé‡_g'] = merged_data['CO2æ’å‡ºé‡_g'].round(5)
            log_messages.append("  - è·é›¢ã¨CO2æ’å‡ºé‡ã‚’å°æ•°ç‚¹ä»¥ä¸‹5æ¡ã«ä¸¸ã‚ã¾ã—ãŸã€‚")
            original_cols = list(sales_data_raw.columns)
            added_cols = ['ä»•å…¥å…ˆ_ç·¯åº¦', 'ä»•å…¥å…ˆ_çµŒåº¦', 'è·å—äºº_ç·¯åº¦', 'è·å—äºº_çµŒåº¦', 'è·é›¢_km', 'CO2æ’å‡ºé‡_g']
            final_cols_exist = [col for col in original_cols + added_cols if col in merged_data.columns]
            result_df_all = merged_data[final_cols_exist].copy()
            normal_result_df = result_df_all[result_df_all['è·é›¢_km'] <= 600].copy()
            anomaly_result_df = result_df_all[result_df_all['è·é›¢_km'] > 600].copy()
            normal_row_count = len(normal_result_df)
            anomaly_row_count = len(anomaly_result_df)
            st.session_state.co2_normal_count = normal_row_count
            st.session_state.co2_anomaly_count = anomaly_row_count
            log_messages.append(f"  - çµæœã‚’åˆ†å‰²ã—ã¾ã—ãŸ (æ­£å¸¸: {normal_row_count}ä»¶, ç•°å¸¸å€¤ç–‘ã„: {anomaly_row_count}ä»¶)ã€‚")
            st.session_state.co2_processing_done = True
            st.session_state.co2_normal_result_df = normal_result_df
            st.session_state.co2_anomaly_result_df = anomaly_result_df
            st.session_state.co2_log_messages = log_messages
            progress_bar.progress(1.0, text="å‡¦ç†å®Œäº†ï¼")
            st.success("CO2æ’å‡ºé‡è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        except ValueError as ve:
            st.error(f"å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ: {ve}")
            st.session_state.co2_error_message = str(ve)
            st.session_state.co2_log_messages = log_messages
            progress_bar.empty()
        except Exception as e:
            st.error(f"å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.exception(e) # ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚‚è¡¨ç¤º
            st.session_state.co2_error_message = str(e)
            st.session_state.co2_log_messages = log_messages
            progress_bar.empty()


# ---- çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢ ----
if st.session_state.get('co2_button_clicked', False):
    if st.session_state.get('co2_error_message'):
        with res_col2:
            st.error("ã‚¨ãƒ©ãƒ¼ã®ãŸã‚å‡¦ç†ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°ã¨ãƒ­ã‚°ã‚’è¡¨ç¤º", expanded=True):
                st.error(st.session_state.co2_error_message)
                log_messages = st.session_state.get('co2_log_messages', ["ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"])
                st.code('\n'.join(log_messages), language='text')
    elif st.session_state.get('co2_processing_done', False):
        with res_col2:
            st.subheader("å‡¦ç†çµæœæ¦‚è¦")
            input_count = st.session_state.get('co2_input_count', 0)
            normal_count = st.session_state.get('co2_normal_count', 0)
            anomaly_count = st.session_state.get('co2_anomaly_count', 0)
            total_output_count = normal_count + anomaly_count
            count_col1, count_col2, count_col3, count_col4 = st.columns(4)
            with count_col1: st.metric("å…¥åŠ›è²©å£²å®Ÿç¸¾ ä»¶æ•°", f"{input_count:,}")
            with count_col2: st.metric("æ­£å¸¸çµæœ ä»¶æ•° (<=600km)", f"{normal_count:,}")
            with count_col3: st.metric("ç•°å¸¸å€¤ç–‘ã„ ä»¶æ•° (>600km)", f"{anomaly_count:,}")
            with count_col4: st.metric("å‡ºåŠ›åˆè¨ˆ ä»¶æ•°", f"{total_output_count:,}", delta=f"{total_output_count - input_count:,}", delta_color="off" if total_output_count == input_count else "inverse")
            if input_count == total_output_count: st.success("âœ… å…¥åŠ›ä»¶æ•°ã¨å‡ºåŠ›åˆè¨ˆä»¶æ•°ãŒä¸€è‡´ã—ã¾ã—ãŸã€‚")
            else: st.warning("âš ï¸ å…¥åŠ›ä»¶æ•°ã¨å‡ºåŠ›åˆè¨ˆä»¶æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚å‡¦ç†ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.divider()
            st.markdown("##### è¨ˆç®—çµæœ (è·é›¢ <= 600km)")
            normal_df = st.session_state.get('co2_normal_result_df', pd.DataFrame())
            st.dataframe(normal_df, use_container_width=True, height=300)
            if not normal_df.empty:
                if uploaded_sales_files: base_filename = uploaded_sales_files[0].name.split('.')[0]; download_filename_normal = f"{base_filename}_co2_result_normal.csv"
                else: download_filename_normal = "co2_result_normal.csv"
                normal_csv = normal_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button("ğŸ“¥ æ­£å¸¸çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (<= 600km)", normal_csv, download_filename_normal, "text/csv")
            else: st.caption("æ­£å¸¸çµæœ (è·é›¢ <= 600km) ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.divider()
            st.markdown("##### è¨ˆç®—çµæœ (è·é›¢ > 600km) - ç•°å¸¸å€¤ã®å¯èƒ½æ€§")
            anomaly_df = st.session_state.get('co2_anomaly_result_df', pd.DataFrame())
            st.dataframe(anomaly_df, use_container_width=True, height=200)
            if not anomaly_df.empty:
                if uploaded_sales_files: base_filename = uploaded_sales_files[0].name.split('.')[0]; download_filename_anomaly = f"{base_filename}_co2_result_anomaly.csv"
                else: download_filename_anomaly = "co2_result_anomaly.csv"
                anomaly_csv = anomaly_df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button("ğŸ“¥ ç•°å¸¸å€¤ç–‘ã„çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (> 600km)", anomaly_csv, download_filename_anomaly, "text/csv")
            else: st.caption("ç•°å¸¸å€¤ç–‘ã„çµæœ (è·é›¢ > 600km) ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            with st.expander("å‡¦ç†ãƒ­ã‚°ã‚’è¡¨ç¤º"):
                log_messages = st.session_state.get('co2_log_messages', ["ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"])
                st.code('\n'.join(log_messages), language='text')
elif not all_files_uploaded and (st.session_state.get("sales_uploader_co2") is not None or st.session_state.get("geocoded_list_uploader") is not None):
     with res_col1: st.warning("å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
else:
     with res_col2: st.caption("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã€ã€Œå‡¦ç†å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")